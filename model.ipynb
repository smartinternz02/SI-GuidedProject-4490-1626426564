{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PNEUMONIA DETECTION USING CONVOLUTIONAL NEURAL NETWORKS(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing LIBRARIES\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the path of the data(train,test,validaton)\n",
    "\n",
    "train = 'C:/Users/hi/Desktop/sb/pro/pne/chest_xray/train'\n",
    "test = 'C:/Users/hi/Desktop/sb/pro/pne/chest_xray/test'\n",
    "val = 'C:/Users/hi/Desktop/sb/pro/pne/chest_xray/val'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are using tensorflow backend v  ,so we go for channel_last ie to specify the channel value as the last dimension in shape of the input.\n",
    "img_width,img_height= 150,150\n",
    "input_shape = (img_width,img_height,3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Itâ€™s just a thing function that you use to get the output of node. It is also known as Transfer Function.\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# The number of filters are 32 and the kernal_size is (3,3)\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(50))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(50))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(50))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we use RMSPROP optimizer and BINARY_CROSSENTROPY as loss function  \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 15, 15, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 913,761\n",
      "Trainable params: 913,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ImageDataGenerator-Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches).\n",
    "batch_size = 16\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Here we import images directly from Directory by using flow_from_directory method.\n",
    "#flow_from_directory() automatically infers the labels from the directory structure of the folders containing images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    val,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hi\\Anaconda3\\envs\\new\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "326/326 [==============================] - 251s 771ms/step - loss: 0.4586 - acc: 0.8069 - val_loss: 0.5251 - val_acc: 0.6875\n",
      "Epoch 2/20\n",
      "326/326 [==============================] - 216s 661ms/step - loss: 0.2658 - acc: 0.8995 - val_loss: 0.5447 - val_acc: 0.6875\n",
      "Epoch 3/20\n",
      "326/326 [==============================] - 211s 648ms/step - loss: 0.2036 - acc: 0.9252 - val_loss: 0.5080 - val_acc: 0.8125\n",
      "Epoch 4/20\n",
      "326/326 [==============================] - 214s 656ms/step - loss: 0.1876 - acc: 0.9312 - val_loss: 0.5804 - val_acc: 0.6875\n",
      "Epoch 5/20\n",
      "326/326 [==============================] - 220s 674ms/step - loss: 0.1827 - acc: 0.9312 - val_loss: 0.6717 - val_acc: 0.6875\n",
      "Epoch 6/20\n",
      "326/326 [==============================] - 215s 660ms/step - loss: 0.1670 - acc: 0.9385 - val_loss: 0.8058 - val_acc: 0.6250\n",
      "Epoch 7/20\n",
      "326/326 [==============================] - 215s 661ms/step - loss: 0.1641 - acc: 0.9406 - val_loss: 0.8793 - val_acc: 0.6875\n",
      "Epoch 8/20\n",
      "326/326 [==============================] - 213s 652ms/step - loss: 0.1650 - acc: 0.9406 - val_loss: 3.4549 - val_acc: 0.5625\n",
      "Epoch 9/20\n",
      "326/326 [==============================] - 213s 655ms/step - loss: 0.1770 - acc: 0.9452 - val_loss: 0.7773 - val_acc: 0.6875\n",
      "Epoch 10/20\n",
      "326/326 [==============================] - 215s 660ms/step - loss: 0.1513 - acc: 0.9477 - val_loss: 1.0350 - val_acc: 0.6250\n",
      "Epoch 11/20\n",
      "326/326 [==============================] - 214s 657ms/step - loss: 0.1535 - acc: 0.9482 - val_loss: 0.4967 - val_acc: 0.8750\n",
      "Epoch 12/20\n",
      "326/326 [==============================] - 212s 649ms/step - loss: 0.1440 - acc: 0.9530 - val_loss: 1.1475 - val_acc: 0.7500\n",
      "Epoch 13/20\n",
      "326/326 [==============================] - 210s 645ms/step - loss: 0.1554 - acc: 0.9427 - val_loss: 1.2818 - val_acc: 0.6250\n",
      "Epoch 14/20\n",
      "326/326 [==============================] - 203s 624ms/step - loss: 0.1910 - acc: 0.9457 - val_loss: 2.0747 - val_acc: 0.5625\n",
      "Epoch 15/20\n",
      "326/326 [==============================] - 144s 443ms/step - loss: 0.6086 - acc: 0.9300 - val_loss: 1.0225 - val_acc: 0.6250\n",
      "Epoch 16/20\n",
      "326/326 [==============================] - 147s 451ms/step - loss: 0.1520 - acc: 0.9509 - val_loss: 1.5443 - val_acc: 0.6250\n",
      "Epoch 17/20\n",
      "326/326 [==============================] - 150s 461ms/step - loss: 0.1565 - acc: 0.9500 - val_loss: 1.6709 - val_acc: 0.6250\n",
      "Epoch 18/20\n",
      "326/326 [==============================] - 147s 449ms/step - loss: 0.1607 - acc: 0.9496 - val_loss: 0.3206 - val_acc: 0.8750\n",
      "Epoch 19/20\n",
      "326/326 [==============================] - 147s 451ms/step - loss: 0.1533 - acc: 0.9538 - val_loss: 0.8760 - val_acc: 0.6250\n",
      "Epoch 20/20\n",
      "326/326 [==============================] - 151s 463ms/step - loss: 0.1547 - acc: 0.9536 - val_loss: 0.6680 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x271683e0518>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We Fit the model here using fit_generator as we are dealing with large datasets.\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=5217 // 16,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=17 // 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc: 90.87%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of test data.\n",
    "test_acc = model.evaluate_generator(test_generator,624/16)\n",
    "print(\"\\nAccuracy:\"+\" %.2f%%\" % ( test_acc[1]*100))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model in H5 format.\n",
    "model.save('pnemonia.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model in Json format.\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying images of Normal and Pneumonia\n",
    "img_n = load_img('C:/Users/hi/Desktop/sb/pro/pne/chest_xray/train/NORMAL/IM-0234-0001.jpeg')\n",
    "plt.imshow(img_n)\n",
    "plt.title(\"Normal\")\n",
    "plt.show()\n",
    "\n",
    "img_p = load_img('C:/Users/hi/Desktop/sb/pro/pne/chest_xray/train/PNEUMONIA/person7_bacteria_24.jpeg')\n",
    "plt.imshow(img_p)\n",
    "plt.title(\"Pneumonia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98931956]]\n",
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "model = load_model('models/vison_v1.0.h5')\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "from skimage.transform import resize\n",
    "\n",
    "def detect(frame):\n",
    "    try:\n",
    "        img = resize(frame,(150,150))\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "        #if(np.max(img)>1):\n",
    "         #   img = img/255.0\n",
    "        prediction = model.predict(img)\n",
    "        print(prediction)\n",
    "        prediction = model.predict_classes(img)\n",
    "        print(prediction)\n",
    "    except AttributeError:\n",
    "        print(\"shape not found\")\n",
    "\n",
    "frame=cv2.imread(\"test.jpg\")\n",
    "data = detect(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
